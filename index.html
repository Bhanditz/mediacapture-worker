<!DOCTYPE html>
<html>
  <head>
    <title>Media Capture Stream with Video Worker</title>
    <meta charset='utf-8'>
    <script src='https://www.w3.org/Tools/respec/respec-w3c-common'
            async class='remove'></script>
    <script class='remove'>
      var respecConfig = {
          // specification status (e.g. WD, LCWD, WG-NOTE, etc.). If in doubt use ED.
          specStatus:           "ED",

          // the specification's short name, as in http://www.w3.org/TR/short-name/
          shortName:            "mediacapture-worker",

          // if your specification has a subtitle that goes below the main
          // formal title, define it here
          // subtitle   :  "an excellent document",

          // if you wish the publication date to be other than the last modification, set this
          // publishDate:  "2009-08-06",

          // if the specification's copyright date is a range of years, specify
          // the start date here:
          // copyrightStart: "2005"

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
          // previousPublishDate:  "1977-03-15",
          // previousMaturity:  "WD",

          // if there a publicly available Editor's Draft, this is the link
           edDraftURI:           "http://chiahungtai.github.io/mediacapture-worker/",

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2009-08-05",

          // editors, add as many as you like
          // only "name" is required
          editors:  [
              {
                  name:       "Chia-hung Tai"
//              ,   url:        "http://example.org/"
              ,   mailto:     "ctai@mozilla.com"
              ,   company:    "Mozilla"
              ,   companyURL: "https://www.mozilla.org/en-US/foundation/moco/"
              },
              {
                  name:       "Robert O'Callahan"
//              ,   url:        "http://example.org/"
              ,   company:    "Mozilla"
              ,   companyURL: "https://www.mozilla.org/en-US/foundation/moco/"
              },
              {
                  name:       "Tzuhao Kuo"
//              ,   url:        "http://example.org/"
              ,   mailto:     "tkuo@mozilla.com"
              ,   company:    "Mozilla"
              ,   companyURL: "https://www.mozilla.org/en-US/foundation/moco/"
              },
          ],

          // name of the WG
          wg:           "Web Real-Time Communication Working Group",

          // URI of the public WG page
          wgURI:        "http://www.w3.org/2011/04/webrtc/",

          // name (without the @w3c.org) of the public mailing to which comments are due
          wgPublicList: "public-media-capture",

          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "",
          // !!!! IMPORTANT !!!! MAKE THE ABOVE BLINK IN YOUR HEAD
      };
    </script>
  </head>
  <body>
    <section id='abstract'>
      <p>
        This specification extends the <em>Media Capture and Streams</em>
        specification [[!GETUSERMEDIA]] to allow JavaScript developers to
        process video frame data in workers on the web applications.
      </p>
    </section>

    <section id='sotd'>
      <p>
        This document is not complete and is subject to change. Early
        experimentations are encouraged to allow the Media Capture Task Force
        to evolve the specification based on technical discussions within the
        Task Force, implementation experience gained from early
        implementations, and feedback from other groups and
        individuals.
      </p>
    </section>
    <section>
      <h2>Introduction</h2>
      <p>
        The <em>Media Capture and Streams</em> specification provides a way to
        access to the video camera. But how to process the video frame data in
        JavaScript is not covered. By associating a worker with
        <a><code>MediaStreamTrack</code></a>s
        (<code>MediaStreamTrack.kind</code> must be "video"), the framework can
        dispatch a <a><code>VideoProcessEvent</code></a> to the worker frame by
        frame. Then JavaScript developer can write a video processing script
        which enables processing, analyzing of video data directly using
        JavaScript in a Worker thread.
      </p>
      <p>
        <img alt= "The relationship between VideoWorker and MediaStreamTrack"
        src= "images/VideoWorker - FLOW.png">
      </p>
      <p>
        The design principle of this specification is to provide a push-like
        mechanism for video processing. This design gives the Web developers no
        worry about any platform capability to full utilize the CPU usage. The
        Web developer no longer need to decide the FPS rate to grab the input
        video frame. The User Agent only dispatch the VideoProcessEvent when a
        new video frame arriving.
      </p>
    </section>
    <section>
      <h2>Use cases and requirements</h2>
      <p>
        This specification attempts to address the
        <a href="https://wiki.mozilla.org/Project_FoxEye#Use_Cases">Use Cases
        and Requirements </a>for expanding the Web potentials to image
        processing and computer vision area. 
      </p>
    </section>
    <section>
      <h2>Conformance</h2>
      <p>
        This specification defines conformance criteria that apply to a single
        product: the <dfn>user agent</dfn> that implements the interfaces that
        it contains.
      </p>
      <p>
        Implementations that use ECMAScript to implement the APIs defined in
        this specification must implement them in a manner consistent with the
        ECMAScript Bindings defined in the Web IDL specification [[!WEBIDL]],
        as this specification uses that specification and terminology.
      </p>
      <p>
        The key words "MUST", "MUST NOT", "REQUIRED", "SHOULD", "SHOULD NOT",
        "RECOMMENDED", "MAY", and "OPTIONAL" in the normative parts of this
        document are to be interpreted as described in RFC2119. For readability,
        these words do not appear in all uppercase letters in this
        specification. [[!RFC2119]]
      </p>
    </section>
    <section>
      <h2>Dependencies</h2>
      <p>
        Under Construction...
      </p>
    </section>
    <section>
      <h2>Terminology</h2>
      <p>
        Under Construction...
      </p>
    </section>
    <section>
      <h2>Extensions</h2>
        <section>
          <h2>
            <code>VideoWorker</code> interface
          </h2>
          <p>
            A <code><a>VideoWorker</a></code> object is the main-thread representation
            of a worker "thread" that support processing of video in JavaScript.
            These main thread objects cause the instantiation of a Web
            Worker-like thread context (Described in [[!Workers]]), which
            executes in the video thread.
          </p>
          <dl class="idl" title="[Constructor(DOMString scriptURL)] interface
          VideoWorker : Worker">
            <dt>void terminate()</dt>
            <dd>
              The <code>terminate()</code> method, when invoked, must cause the 
              <a href="http://dev.w3.org/html5/workers/#terminate-a-worker">
              "terminate a worker"</a> algorithm to be run on the worker with
              which the object is associated.  This will cease any
              <code><a>VideoProcessEvent</a></code>s being dispatched inside the 
              VideoWorker's associated <code><a>VideoWorkerGlobalScope</a></code>,
              will cause all associated <code>MediaStreamTrack</code> to cease
              processing, and will cause the destruction of the worker thread.
            </dd>
            <dt>
              [Throws]
              void postMessage(any message, optional sequence&lt;any&gt; transfer)
            </dt>
            <dd>
              <code>postMessage()</code> is used to send a message to the
              <code><a>VideoWorkerGlobalScope</a></code> via the algorithm
              defined by [[!Workers]].
            </dd>
            <dt>
              attribute EventHandler onmessage
            </dt>
            <dd>
              The <code>onmessage()</code> handler is called whenever the
              <code><a>VideoWorkerGlobalScope</a></code> posts a message back to the
              main thread.
            </dd>
          </dl>
        </section>
        <section>
          <h2>
            <code>VideoWorkerGlobalScope</code> interface
          </h2>
          <p>
           This interface is a <code>DedicatedWorkerGlobalScope</code>-derived
           object representing the context in which an video processing script
           runs; it is designed to enable the generating, processing, and
           analyzing of video data directly using JavaScript in a Worker thread.
          </p>
          <p>
            The <code><a>VideoWorkerGlobalScope</a></code> is the "inside" of a
            <code><a>VideoWorker</a></code>. It must not exist if the interface's
            relevant namespace object is not a
            <code><a>VideoWorkerGlobalScope</a></code> object.
          </p>
          <dl class="idl" title="interface VideoWorkerGlobalScope : WorkerGlobalScope ">
            <dt>
              [Throws]
              void postMessage(any message, optional sequence&lt;any&gt; transfer)
            </dt>
            <dd>
              The <code>postMessage()</code> method of
              <code><a>VideoWorkerGlobalScope</a></code> objects must act like
              the method in <code>DedicatedWorkerGlobalScope</code>.
            </dd>
            <dt>
              attribute EventHandler onmessage
            </dt>
            <dd>
              The event handler, of type <code>message</code>, is executed when
              a message is post from parent. It must act like the attribute in
              <code>DedicatedWorkerGlobalScope</code>.
            </dd>
            <dt>
              attribute EventHandler onvideoprocess
            </dt>
            <dd>
              <p>
                A property used to set the EventHandler (described in [[!HTML]])
                for the <code><a>VideoProcessEvent</a></code> that is dispatched
                to <code><a>VideoWorkerGlobalScope</a></code> to process video
                while the associated <code><a>MediaStreamTrack</a></code> are
                connected. When a new input video frame is sent to corresponding
                <code>MediaStreamTrack</code>, User Agent will create a
                <code><a>VideoProcessEventThe</a></code> and dispatch it. Then the event
                handler, of type 
                <code><a href="#event-videoprocessevent">videoprocess</a></code>,
                is executed .
               </p>
            </dd>
          </dl>
        </section>
        <section>
          <h2>
            <code id = event-videoprocessevent>VideoProcessEvent</code> interface
          </h2>
          <p>
            This is an <code>Event</code> object which is dispatched to
            <a><code>VideoWorkerGlobalScope</code></a> objects to perform
            processing.
          </p>
          <p>
            When the <code>MediaStreamTrack</code> comes a new video frame data,
            the User Agent will dispatch a <code>VideoProcessEvent</code>.
            The event handler processes video from the input by accessing the
            video data from the <code>inputImageBitmap</code> attribute in the
            <code>VideoProcessEvent</code>. The processed video data which is
            the result of the processing is then placed into the
            <code>outputImageBitmap</code>. The User Agent will append the
            <code>outputImageBitmap</code> into the new created
            <code>MediaStreamTrack</code>.
          </p>
          <p>
            Ideally the <code>MediaStreamTrack</code> should dispatch each
            video frame through <a>VideoProcessEvent</a>. But sometimes the
            worker thread could not process the frame in time. So the
            implementation could skip the frame to avoid high memory footprint.(??TODO. need to discuss it.)
            In such case, we might not be able to process every frame in a real
            time <code>MediaStream</code>.
          </p>
          <dl class="idl" title="interface VideoProcessEvent : Event">
            <dt>
              readonly attribute DOMString trackId
            </dt>
            <dd>
              The <code>MediaStreamTrack.id</code> of corresponding
              <code>MediaStreamTrack</code>.
            </dd>
            <dt>
              readonly attribute double playbackTime
            </dt>
            <dd>
              The elapsed time of the <code>MediaStreamTrack</code> from the
              <code>MediaStream</code> starting.
            </dd>
            <dt>
              readonly attribute ImageBitmap inputImageBitmap
            </dt>
            <dd>
              The input video frame comes from the corresponding
              <code>MediaStreamTrack</code>.
            </dd>
            <dt>
              readonly attribute ImageBitmap? outputImageBitmap
            </dt>
            <dd>
              The output video frame comes to the corresponding
              <code>MediaStreamTrack</code>. It is null when the
              <a>VideoWorker</a> is added by function
              <code>AddWorkerMonitor</code>.
            </dd>
          </dl>
        </section>
        <section>
          <h2>
            <code>MediaStreamTrack</code> interface
          </h2>
          <dl class="idl" title="partial interface MediaStreamTrack">
            <dt>
              void addWorkerMonitor(VideoWorker worker)
            </dt>
            <dd>
              Associate the <code>worker</code> with the <code>MediaStreamTrack</code>.
              You can add the same <code>worker</code> to any other
              <code>MediaStreamTrack</code>.
            </dd>
            <dt>
              void removeWorkerMonitor(VideoWorker worker)
            </dt>
            <dd>
              Remove a particular <a>VideoWorker</a> from the
              <code>MediaStreamTrack</code>. User Agent should throw exception
              when the <a>VideoWorker</a> is not exist in the
              <code>MediaStreamTrack</code>.
            </dd>
            <dt>
              MediaStreamTrack addWorkerProcessor(VideoWorker worker)
            </dt>
            <dd>
              This method will create a new <code>MediaStreamTrack</code> and
              take the original <code>MediaStreamTrack</code> as the input
              source. Then associate the <a>VideoWorker</a> with new created
              <code>MediaStreamTrack</code>. The developers can build a
              processed pipeline by this method.
            </dd>
            <dt>
              void removeWorkerProcessor()
            </dt>
            <dd>
              Remove the added <a>VideoWorker</a> from current
              <code>MediaStreamTrack</code>. User Agent should throw exception
              when the <a>VideoWorker</a> is not exist in the
              <code>MediaStreamTrack</code>. A <code>MediaStreamTrack</code>
              owns at most one VideoWorker processor in any time.
            </dd>
          </dl>
        </section>
    </section>
    <section>
      <h2>Examples</h2>
      <h3>
        WorkerMonitor example:
      </h3>
      <p>
        This example demonstrates how to hook a <code><a>VideoWorker</a></code> with a
        <code>MediaStreamTrack</code> and also shows how to use
        <code>postMessage</code> to communicate between main thread and worker
        thread. In this example, the role of control_worker.js is doing flow control.
        This script decide whether drop frame or not. If the system is not busy,
        the script will dispatch current frame to process_worker.js or it just
        drop the frame.
      </p>
      <h4>
        Main file javascript
      </h4>
      <pre class='example highlight'>
        playButton.onclick = function() {
          navigator.getUserMedia({video: true, audio: false} , onSuccess, onFail);
        }
        function onSuccess(stream) {
            localMediaStream = stream;
            initControlWorker();
            if (showWebCamVideo) {
                video.src = window.URL.createObjectURL(localMediaStream);
                video.play();
            }
        }
        function initControlWorker() {
          controlWorker = new VideoWorker("control_worker.js");
          if (!!controlWorker) {
            var tracks = localMediaStream.getTracks();
            controlWorker.postMessage({"type":"set_trackid", "id":tracks[0].id});
            controlWorker.postMessage({"type":"init_process_worker"});
            tracks[0].addWorkerMonitor(controlWorker);
          }
          controlWorker.onmessage = function(event) {
            if(event.data.type == "display_arraybuffer") {
              if (!isCanvasInitialized) {
                canvasResult.width = event.data.bitmap.width;
                canvasResult.height = event.data.bitmap.height;
                isCanvasInitialized = true;
              }
              // show result
              ctxResult.drawImage(event.data.bitmap, 0, 0);
            }
          };
        }
      </pre>
      <h4>
        control_worker.js
      </h4>
      <pre class='example highlight'>
        var trackid;
        var worker;
        var isProcessing = false;
        var processWorker;
        onmessage = function(event) {
          if (event.data.type == "init_process_worker") {
            processWorker = new Worker("process_worker.js");
        
            processWorker.onmessage = function(event) {
              if (event.data.type == "display_arraybuffer") {
                // send back to the main thread
                postMessage({"type":event.data.type,
                             "bitmap":event.data.bitmap});
                isProcessing = false;
              }
            };
          } else if (event.data.type == "set_trackid") {
            trackid = event.data.id;
          }
        }
        
        var frameNum = 0;
        var dropNum = 0;
        
        function showDropRate() {
          console.log("Drop rate = " + 100 * dropNum / frameNum + "%");
        }
        
        onvideoprocess = function(event) {
          if (frameNum % 100 == 1) {
            showDropRate();
          }
        
          frameNum++;
          if (isProcessing) {
            // drop this frame
            console.log("drop frame[" + frameNum + "]");
            dropNum++;
            return;
          } else {
            // console.log("process frame[" + frameNum + "]")
            isProcessing = true;
            // send to the process worker
            processWorker.postMessage({"type":"convert_color",
                                       "bitmap":event.inputImageBitmap});
          }
        };
      </pre>
      <h4>
        process_worker.js
      </h4>
      <pre class='example highlight'>
        function processOneFrame_RGBA(bitmap) {
          // Do what you want to do!
          ...
        }
        onmessage = function(event) {
          // do the invernt effect
          processOneFrame_RGBA(event.data.bitmap);

          // send back to the control worker
          postMessage({"type":"display_arraybuffer",
                       "bitmap":event.data.bitmap});
        };
      </pre>
      <h3>
        WorkerMonitor example in multiple workers:
      </h3>
      <p>
        This example is extended from previous "WorkerMonitor example". The main
        difference is this example create a WorkerPool object in
        control_worker.js. The script will reuse the workers in the pool. This
        mechanism full utilized the power of multi-core machine to reduce the
        frame drop rate.
      </p>
      <h4>
        Main file javascript
      </h4>
      <pre class='example highlight'>
        playButton.onclick = function() {
            navigator.getUserMedia({video: true, audio: false} , onSuccess, onFail);
        }
        stopButton.onclick = function() {
            isContinuous = false;
            video.pause();
            localMediaStream.stop();
        }
        function onSuccess(stream) {
            localMediaStream = stream;
            initControlWorker();
            if (showWebCamVideo) {
                video.src = window.URL.createObjectURL(localMediaStream);
                video.play();
            }
        }
        function onFail(e) {
            console.log('Cannot access WebCAM!', e);
        }
        function initControlWorker() {
          controlWorker = new VideoWorker("control_worker.js");
          if (!!controlWorker) {
            var tracks = localMediaStream.getTracks();
            controlWorker.postMessage({"type":"set_trackid", "id":tracks[0].id});
            controlWorker.postMessage({"type":"init_process_worker"});
            tracks[0].addWorkerMonitor(controlWorker);
          }
          controlWorker.onmessage = function(event) {
            if (event.data.taskType == "DisplayTask") {
              if (!isCanvasInitialized) {
                canvasResult.width = event.data.bitmap.width;
                canvasResult.height = event.data.bitmap.height;
                isCanvasInitialized = true;
              }
              ctxResult.drawImage(event.data.bitmap, 0, 0);
            }
          };
        }
      </pre>
      <h4>
        control_worker.js
      </h4>
      <pre class='example highlight'>
        /*
         * WorkerPool
         */
        function WorkerPool() {
          this.avaialableQueue = [];
          this.workingQueue = [];
        }
        
        WorkerPool.prototype.Init = function(script, numOfWorkers) {
          for (var i = 0; i < numOfWorkers; ++i) {
            this.avaialableQueue.push(new ProcessWorker(i, script, this));
          }
        }
        
        WorkerPool.prototype.Process = function(frameNum, bitmap) {
          var task = new ProcessTask(frameNum, bitmap);
          return this.Dispatch(task);
        }
        
        WorkerPool.prototype.Dispatch = function(task) {
          if (task.taskType == ProcessTask.TASK_TYPE) {
            if (this.avaialableQueue.length > 0) {
              var processWorker = this.avaialableQueue.shift();
              processWorker.worker.postMessage(task);
              this.workingQueue.push(processWorker);
              return true;
            }
            else {
              console.log("No availabe ProcessWorker now, drop this frame[" + task.frameNum + "]......");
              return false;
            }
          } else {
            console.log("Cannot handle " + task.taskType);
            return false;
          }
        }
        
        WorkerPool.prototype.Display = function() {
          while(this.workingQueue.length > 0) {
            if (!!(this.workingQueue[0].displayTask)) {
              var processWorker = this.workingQueue.shift();
              postMessage(processWorker.displayTask);
              processWorker.displayTask = null;
              this.avaialableQueue.push(processWorker);
            } else {
              break;
            }
          }
        }
        
        WorkerPool.prototype.FindProcessWorker = function(worker) {
          for (var i = 0; i < this.workingQueue.length; ++i) {
            if (this.workingQueue[i].worker == worker) {
              return this.workingQueue[i];
            }
          }
        }
        
        /*
         * ProcessWorker
         */
        function ProcessWorker(id, script, pool) {
          this.workerID = id;
          this.workerPool = pool
          this.displayTask = null;
          this.worker = new Worker(script);
          this.worker.wraper = this;
          this.worker.onmessage = function(event) {
            var processWorker = workerPool.FindProcessWorker(this);
            processWorker.displayTask = new DisplayTask(event.data.frameNum, event.data.bitmap);
            workerPool.Display();
            // workerPool.PrintInfo("in worker.onmessage()");
          }
        }
        
        /*
         * Task, ProcessTask, DisplayTask
         */
        function Task(type, frameNum) {
          this.taskType = type;
          this.frameNum = frameNum;
        }
        
        function ProcessTask(frameNum, bitmap) {
          Task.call(this, ProcessTask.TASK_TYPE, frameNum);
          this.bitmap = bitmap;
        }
        ProcessTask.prototype = Object.create(Task.prototype);
        ProcessTask.prototype.constructor = ProcessTask;
        ProcessTask.TASK_TYPE = "ProcessTask";
        
        function DisplayTask(frameNum, bitmap) {
          Task.call(this, DisplayTask.TASK_TYPE, frameNum);
          this.bitmap = bitmap;
        }
        DisplayTask.prototype = Object.create(Task.prototype);
        DisplayTask.prototype.constructor = DisplayTask;
        DisplayTask.TASK_TYPE = "DisplayTask";
        var numOfWorkers = 2; // initialize the WorkerPool whit this number of workers.
        var workerPool;
        var trackid;
        var frameNum = 0;
        var dropNum = 0;
        
        function showDropRate() {
          console.log("Drop rate = " + 100 * dropNum / frameNum + "%");
        }
        
        
        onmessage = function(event) {
          if (event.data.type == "init_process_worker") {
            workerPool = new WorkerPool();
            workerPool.Init("process_worker.js", numOfWorkers);
          } else if (event.data.type == "set_trackid") {
            trackid = event.data.id;
          }
        }
        
        onvideoprocess = function(event) {
          if (frameNum % 100 == 1) {
            showDropRate();
          }
        
          if (!workerPool.Process(frameNum++, event.inputImageBitmap)) {
            dropNum++;
          }
        };
      </pre>
      <h4>
        process_worker.js
      </h4>
      <pre class='example highlight'>
        function processOneFrame_RGBA(bitmap) {
          // Do what you want to do!
          ...
        }
        onmessage = function(event) {
          // do the invernt effect
          processOneFrame_RGBA(event.data.bitmap);

          // send back to the control worker
          postMessage({"type":"display_arraybuffer",
               "frameNum":event.data.frameNum,
               "bitmap":event.data.bitmap});
        };
      </pre>
      <h3>
        WorkerProcessor example:
      </h3>
      <p>
        This example shows how to process and display the processed
        <a>MediaStreamTrack</a>. Be careful, the <a>VideoWorker</a> is appended
        into the new <a>MediaStreamTrack</a>, not original one.
      </p>
      <h4>
        Main file javascript
      </h4>
      <pre class='example highlight'>
        playButton.onclick = function() {
            navigator.getUserMedia({video: true, audio: false} , onSuccess, onFail);
        }
        stopButton.onclick = function() {
            isContinuous = false;
            video.pause();
            localMediaStream.stop();
        }
        function onSuccess(stream) {
            localMediaStream = stream;
            initControlWorker();
            if (showWebCamVideo) {
                video.src = window.URL.createObjectURL(localMediaStream);
                video.play();
            }
        }
        function onFail(e) {
            console.log('Cannot access WebCAM!', e);
        }
        function initControlWorker() {
          controlWorker = new VideoWorker("processor.js");
          if (!!controlWorker) {
            var tracks = localMediaStream.getTracks();
            controlWorker.postMessage({"type":"set_trackid", "id":tracks[0].id});
            var newtrack = tracks[0].addWorkerProcessor(controlWorker);
            // link to the result video
            resultVideo.mozSrcObject = new MediaStream([newtrack]);
            resultVideo.play();
          }
          controlWorker.onmessage = function(event) {
            if(event.data.type == "display_arraybuffer") {
              if (!isCanvasInitialized) {
                resultVideo.width = event.data.imageWidth;
                resultVideo.height = event.data.imageHeight;
                isCanvasInitialized = true;
              }
            }
          };
        }
      </pre>
      <h4>
        processor.js
      </h4>
      <pre class='example highlight'>
        function processOneFrame_Invert(inputBitmap, outputBitmap) {
          var bitmap = inputBitmap;
          var format = bitmap.findOptimalFormat();
          format = "RGBA32"; // force it to be RGBA32, do conversion in Gecko
          var length = bitmap.mappedDataLength(format);
        
          if (format != bitmapFormat || length != bitmapBufferLength) {
            bitmapFormat = format;
            bitmapBufferLength = length;
            bitmapBuffer = new ArrayBuffer(bitmapBufferLength);
            bitmapBufferView = new Uint8ClampedArray(bitmapBuffer, 0, bitmapBufferLength);
          }
          var bitmapPixelLayout = bitmap.mapDataInto(bitmapFormat, bitmapBuffer, 0, bitmapBufferLength);
        
          if (!isInitialized) {
            rgbaBufferLength = bitmapBufferLength;
            rgbaBuffer = new ArrayBuffer(rgbaBufferLength);
            rgbaBufferView = new Uint8ClampedArray(rgbaBuffer, 0, rgbaBufferLength);
        
            isInitialized = true;
          }
        
          // convert YUV to Gray or RGBA
          for (var i = 0; i < bitmap.height; ++i) {
            for (var j = 0; j < bitmap.width; ++j) {
        
              /*
               *  do invert effect
               */
              var index = bitmap.width * i + j;
              rgbaBufferView[index * 4 + 0] = 255 - bitmapBufferView[index * 4 + 0];
              rgbaBufferView[index * 4 + 1] = 255 - bitmapBufferView[index * 4 + 1];
              rgbaBufferView[index * 4 + 2] = 255 - bitmapBufferView[index * 4 + 2];
              rgbaBufferView[index * 4 + 3] = bitmapBufferView[index * 4 + 3]; // no change in the appha channel
            }
          }
        
          // write back to event outputImageBitmap
          outputBitmap.setDataFrom("RGBA32", rgbaBuffer, 0, rgbaBufferLength,
                                   bitmap.width, bitmap.height, bitmapPixelLayout.channels[0].stride);
        }
        onvideoprocess = function(event) {
          processOneFrame_Invert(event.inputImageBitmap, event.outputImageBitmap);
        }
      </pre>
    </section>
    <section class='appendix'>
      <h2>Acknowledgements</h2>
      <p>
        Thanks to Robert O'Callahan for his idea of this design.
      </p>
    </section>
  </body>
</html>
